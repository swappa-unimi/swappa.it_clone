<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html>
<head>
 <title>Swappa : Uni / Sistemi Operativi - Thread</title>
 <meta http-equiv='Content-Type' content='text/html; charset=ISO-8859-1' />
 <meta http-equiv='Content-Language' content='en' />
 <meta http-equiv='Content-Style-Type' content='text/css' />
 <meta http-equiv="imagetoolbar" content="no" />
 <meta name='MSSmartTagsPreventParsing' content='true' />
 <!--HeaderText--><style type='text/css'><!--
  ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }
  code.escaped { white-space: nowrap; }
  .vspace { margin-top:1.33em; }
  .indent { margin-left:40px; }
  .outdent { margin-left:40px; text-indent:-40px; }
  a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
  a.createlink { text-decoration:none; position:relative; top:-0.5em;
    font-weight:bold; font-size:smaller; border-bottom:none; }
  img { border:0px; }
  
.progress-bar {
	display: block;
	background: transparent; 
	width: 520px;
	font-size: 1px; /* for IE */
	margin: 2px 0;
}

.progress-bar .pb1, .progress-bar .pb2, .progress-bar .pb3, .progress-bar .pb4 {
	display: block; 
	background: #fff; 
	border-left:  1px solid #999; 
	border-right: 1px solid #999;

	overflow: hidden; 
	height: 1px; 
}
.progress-bar .pb1 { margin: 0 4px; background: #999;}
.progress-bar .pb2 { margin: 0 2px; border-width: 0 2px; }
.progress-bar .pb3 { margin: 0 1px; }
.progress-bar .pb4 { height: 11px; padding: 0 3px; }
.progress-bar .pb5 { display: block; background: #eeeeef; overflow:hidden; }

.progress-bar .bar {
	display: block;
	background: #a5bbd8;
	height: 11px;
	padding: 0;
}
.editconflict { color:green; 
  font-style:italic; margin-top:1.33em; margin-bottom:1.33em; }

  table.markup { border:2px dotted #ccf; width:90%; }
  td.markup1, td.markup2 { padding-left:10px; padding-right:10px; }
  table.vert td.markup1 { border-bottom:1px solid #ccf; }
  table.horiz td.markup1 { width:23em; border-right:1px solid #ccf; }
  table.markup caption { text-align:left; }
  div.faq p, div.faq pre { margin-left:2em; }
  div.faq p.question { margin:1em 0 0.75em 0; font-weight:bold; }
  div.faqtoc div.faq * { display:none; }
  div.faqtoc div.faq p.question 
    { display:block; font-weight:normal; margin:0.5em 0 0.5em 20px; line-height:normal; }
  div.faqtoc div.faq p.question * { display:inline; }
   
    .frame 
      { border:1px solid #cccccc; padding:4px; background-color:#f9f9f9; }
    .lfloat { float:left; margin-right:0.5em; }
    .rfloat { float:right; margin-left:0.5em; }
a.varlink { text-decoration:none; }

--></style>
  <link rel='stylesheet' href='../pub/wsplus/wsplus.css' 
    type='text/css' />
  <!--[if IE]><style type='text/css' media='screen'>
    body { behavior:url('http://www.swappa.it/wiki/pub/wsplus/csshover.htc'); }
    .rollover * { visibility: visible; }
  </style><![endif]-->
<script type='text/javascript' src='../pub/syntaxlove/scripts/shCore.js'></script><script type='text/javascript' src='../pub/syntaxlove/scripts/shBrushCSharp.js'></script><script type='text/javascript' src='../pub/syntaxlove/scripts/shBrushCpp.js'></script><script type='text/javascript' src='../pub/syntaxlove/scripts/shBrushJava.js'></script><script type='text/javascript' src='../pub/syntaxlove/scripts/shBrushPerl.js'></script><script type='text/javascript' src='../pub/syntaxlove/scripts/shBrushPhp.js'></script><script type='text/javascript' src='../pub/syntaxlove/scripts/shBrushPython.js'></script><script type='text/javascript' src='../pub/syntaxlove/scripts/shBrushRuby.js'></script> <link type='text/css' rel='stylesheet' href='../pub/syntaxlove/css/shCore.css'/>
  <link type='text/css' rel='stylesheet' href='../pub/syntaxlove/css/shThemeDefault.css'/>
  <script type='text/javascript'>
  	SyntaxHighlighter.config.clipboardSwf = 'http://www.swappa.it/wiki/pub/syntaxlove/scripts/clipboard.swf';
  	SyntaxHighlighter.all();
  </script>  <meta name='robots' content='noindex,nofollow' />

 <style type='text/css'><!--

/* Default Fonts */
body { font-family: Verdana,Arial,Helvetica,sans-serif; }
body, td, th { color:#000000; }
body, td, th { font-size: 10pt; }
small { font-size:0.85em; }
code { white-space: nowrap; }
h1, h2, h3, h4, h5 { margin-top:1em; margin-bottom:0.6em; }
h1 { font-size: 1.9em; }
h2 { font-size: 1.5em; }
h3 { font-size: 1.25em; }
h4 { font-size: 1.06em; }
h5 { font-size: 1.0em; }
ul, ol, pre, dl, p { margin-top:0px; margin-bottom:0px; }

/* Misc. */
body { width:auto; background-color:#ffffff; margin:0px; padding:0.5em; }
img { border-width: 0px; }
.indent { margin-left:30px; }
.outdent { margin-left:30px; text-indent:-30px; }
.vspace { margin-top:1.33em; }

/* Links */
a:link { color:#333333; font-weight:normal; text-decoration:underline; }
a:visited { color:#333333; font-weight:normal; text-decoration:underline; }
a.wikilink:hover { color: #333333; text-decoration:underline; }
a.createlink { text-decoration:none; position:relative; top:-0.5em; font-weight:bold; font-size:smaller; border-bottom:none; }
a.createlinktext { text-decoration:none; border-bottom:1px dotted gray; }
a.varlink { text-decoration:none; }
.apprlink { font-size:smaller; }

/* Print View Page Header */
#printhead { font-size:11pt; border-bottom:2px solid #a0a0a0; margin-bottom:1em; }
#printhead a, #printhead a:visited { font-weight:bold; text-decoration:none; }
#cc { float:right; font-size:11pt; border-bottom:2px solid #a0a0a0; margin-bottom:1em; }

/* Print View Page Footer */
#printfoot { font-family: Arial,Helvetica,Geneva,sans-serif; margin-top:1em; border-top:2px solid #a0a0a0; font-size:7pt; }
  
 --></style>
</head>
<body>
  <div id='printhead'>
    <a href='../index.html' title='Swappa Home'>Swappa</a> :
    <a href='http://www.swappa.it/wiki/Uni' title='Uni Home'>Uni</a> /
    <a href='SO-Thread.html' title='Sistemi Operativi - Thread'>Sistemi Operativi - Thread</a>
    <div id='cc'>
	<a rel="license" target="_blank" href="http://creativecommons.org/licenses/by-nc-sa/2.5/it/">
	<img alt="Creative Commons License" style="border-width:0" height="15" width="80" src="http://i.creativecommons.org/l/by-nc-sa/2.5/it/80x15.png" />
	</a>
    </div>
  </div>
  
<!--PageText-->
<div id='wikitext'>
<p>
<a class='wikilink' href='SistemiOperativi.html'>Torna alla pagina di Sistemi Operativi</a>
</p><hr />
<div class='vspace'></div><pre  style='text-align: center; background-color: #ffe4c4; border: 2px solid #cccccc; font-size: 13pt; padding: 5px;'> <strong>:: Appunti 2.0 ::</strong>
</pre><p class='vspace'  style='text-align: center;'><span  style='background-color: #d9e4f2; font-size: 11pt; padding: 4px; padding-left: 50px; padding-right: 50px;'>Thread</span>
</p>
<div class='vspace'></div><h2>Dal processo tradizionale...</h2>
<p>I <a class='wikilink' href='SO-Processi.html'>processi</a> tradizionali sono programmi in esecuzione con un unico flusso di controllo. Ognuno di essi è un'entità autonoma, ciascuna con il proprio spazio di indirizzamento inaccessibile agli altri. Ma se questa proprietà da un lato garantisce integrità e sicurezza, dall'altro può rappresentare un problema, soprattutto per quelle applicazioni ad alta disponibilità di servizio e basso tempo di risposta (come i server web), dove l'utente - o gli utenti - potrebbero richiedere l'esecuzione di più flussi di controllo nello stesso processo per attività simili.
</p>
<p class='vspace'>Ad esempio ho un server web che accetta le richieste concorrenti di più client per le pagine web e tutti gli oggetti in esse contenute. Se fosse eseguito come un singolo processo riuscirebbe a servire un solo client per volta, facendo lievitare i tempi di attesa di tutti gli altri.<br />Una soluzione semplice potrebbe essere attivare tanti processi che erogano il servizio quante sono le richieste per lo stesso (ovviamente stiamo parlando di sistemi multiprogrammati e multitasking), ma anche in questo caso avrei svantaggi piuttosto rilevanti. In primo luogo sarebbe impossibile prevedere a priori il numero di richieste di accesso, e quindi quanti processi dovrò attivare. In secondo luogo avrei un sistema lento, con una gestione poco furba delle risorse. Se infatti al server web arrivassero più richieste per una stessa pagina, ogni volta il processo di servizio dovrebbe leggerla e inviarla al client, sprecando tempo e spazio.
</p>
<p class='vspace'>Sarebbe dunque bello se operazioni simili su dati diversi operassero in modo più correlato, magari su un'area di memoria centrale condivisa a cui i processi possano accedere in modo nativo e naturale. In particolare, vorrei che le applicazioni rendessero disponibili i propri dati ai processi figli in modo semplice, senza doverli ogni volta ricopiare nei rispettivi spazi di indirizzamento, perché è una soluzione inefficiente.
</p>
<div class='vspace'></div><h2>...al concetto di thread</h2>
<p>E' sulla base di queste necessità che nascono i <strong>thread</strong>, ovvero <em>un gruppo di flussi di esecuzione autonomi sullo stesso programma che accedono alla stessa porzione di memoria centrale</em>. Detto in altre parole, è un mini-processo che vive all'interno di un processo vero, autonomo dal punto di vista dell'esecuzione, ma con la stessa "base di dati" a cui attingere, ovvero quella del processo che lo ha generato.
</p>
<p class='vspace'>Il thread può essere anche considerato come l'unità base dell'utilizzo della CPU, e comprende un identificatore, un program counter, un set di registri e uno stack, e condivide con gli altri thread che appartengono allo stesso processo la sezione di codice, quella dei dati e altre risorse del sistema operativo (ad esempio i file aperti).
</p>
<div class='vspace'></div><h2>Processi multithread</h2>
<p>Se il processo tradizionale (detto <em>pesante</em>) ha un solo thread che fa tutto, un processo <em>multithread</em> è caratterizzato da più flussi di esecuzione di istruzioni in parallelo, operanti contemporaneamente e con parte delle informazioni condivise in memoria centrale. In questo modo ogni thread svolgerà le proprie operazioni e potrà eventualmente trasmetterne i risultati a flussi diversi della computazione, proprio in virtù della condivisione dell'accesso allo stesso spazio di indirizzamento. Ovviamente andranno <a class='wikilink' href='SO-Sincronizzazione.html'>sincronizzati</a> opportunamente, o potrei avere dati inconsistenti (perché ad esempio modificati da altri).
</p>
<p class='vspace'>Un processo multithread è rappresentato nella figura sottostante.
</p><div  style='text-align: center;'><img src='../uploads/Uni/multithread.jpg' alt='' title='' /></div>
<p><br clear='all' />
Si può notare come, pur avendo in comune lo stesso codice, due thread diversi hanno comunque contesti specifici su cui operare (quindi registri e stack separati), in modo da poter eseguire operazioni diverse prese da parti diverse del codice. Se infatti condividessero anche stack e registri, finirebbero inevitabilmente per eseguire le stesse operazioni nello stesso momento.
</p>
<div class='vspace'></div><h2>Benefici</h2>
<p>I benefici della programmazione multithread sono i seguenti:
</p><ul><li><em>prontezza di risposta</em>, dato che l'eventuale disponibilità di thread liberi garantisce una maggiore rapidità nel fornire il servizio all'utente. Ad esempio, un browser multithread può permettere all'utente l'interazione in un thread mentre con un altro carica un'immagine;
</li><li><em>condivisione nativa delle risorse</em>, dei thread tra loro e con il processo a cui essi appartengono;
</li><li><em>economia nell'occupazione delle risorse</em>, risparmiando memoria nella rappresentazione delle informazioni nel sistema. La creazione e la gestione dei thread è più economica di quella dei processi anche in termini di tempo, ad esempio in Solaris la creazione è 30 volte più veloce;
</li><li><em>sfruttabili dai sistemi multiprocessore</em>, dove i thread possono essere eseguiti in parallelo su processori differenti, raggiungendo così una condivisione efficiente e diretta delle informazioni. 
</li></ul><div class='vspace'></div><h2>Supporto</h2>
<p>Il supporto per i thread può essere realizzato a due livelli:
</p><ul><li>nello <em>spazio utente</em>, per gli <em>user thread</em>. Sono supportati al di sopra del kernel e sono gestiti senza che lui ne sappia nulla: è il processo che gestisce i suoi thread interni, il sistema operativo sa solo che esiste, ma non sa cosa fa. Tale supporto è reso possibile dalle librerie di thread, residenti completamente nello spazio utente, che forniscono al programmatore le API per la loro creazione e gestione. Invocare una funzione di libreria si traduce quindi in una chiamata di funzione locale nello spazio utente e non in una chiamata di sistema.
</li><li>nel <em>kernel</em>, per i <em>kernel thread</em>. Sono supportati e gestiti direttamente dal sistema operativo, implementando ad esempio una libreria a livello kernel. Al contrario di prima, in questo caso il codice e le strutture dati della libreria risiedono nello spazio kernel, e quindi l'invocazione a una sua funzione si traduce in una chiamata di sistema.
</li></ul><div class='vspace'></div><h2>Modelli multithread</h2>
<p>Ora che abbiamo distinto thread a livello utente e a livello kernel dobbiamo chiederci come possono essere messi in relazione tra loro, ovvero che <em>modelli multithread</em> sono realizzabili.
</p>
<div class='vspace'></div><ul><li><em>modello molti-a-uno</em>, che riunisce molti thread di livello utente in un unico flusso di controllo sul kernel. La gestione dei thread è fatta dalla libreria nello spazio utente, quindi sarà il programma a dover sincronizzare opportunamente i suoi thread interni in modo che il kernel thread che li gestisce ne veda uno solo. Lo svantaggio di tale mappatura è che se uno dei thread in esecuzione si blocca (ad esempio per un I/O), verranno bloccati di conseguenza tutti gli altri thread che fanno parte del suo gruppo. Per fare un esempio, il thread kernel A gestisce i thread utente Alfa, Beta e Gamma. Se Beta fa un'I/O, si blocca in attesa del risultato. Bloccandosi Beta, anche A si blocca perché è proprio A a dover fornire l'I/O a Beta. Ma se A smazza l'I/O di Beta, allora Alfa e Gamma non possono fare altro che dormire, perché A, che dovrebbe gestirli, non può ascoltarli in quanto impegnato a dare retta all'I/O di Beta! Basta dunque una chiamata bloccante perché tutto il sistema si arresti
</li></ul><div  style='text-align: center;'><img src='../uploads/Uni/molti-a-uno.jpg' alt='' title='' /></div>
<div class='vspace'></div><ul><li><em>modello uno-a-uno</em>, che mappa ciascun thread utente in un kernel thread. Fornisce molta più concorrenza del modello precedente, permettendo ad un thread di essere eseguito nonostante un'eventuale chiamata bloccante da parte di un altro. Consente inoltre su sistemi multiprocessore che più thread siano eseguiti in parallelo su diversi processori. Lo svantaggio di tale modello è che la creazione di un thread utente richiede la creazione del corrispondente kernel thread, con un conseguente overhead di gestione che grava sul sistema operativo diminuendone proporzionalmente l'efficienza complessiva.
</li></ul><div  style='text-align: center;'><img src='../uploads/Uni/uno-a-uno.jpg' alt='' title='' /></div>
<div class='vspace'></div><ul><li><em>modello molti-a-molti</em>, che raggruppa in vario modo i thread a livello utente verso un numero inferiore (o equivalente) di kernel thread. Tale numero può dipendere sia dall'applicazione che dalla macchina utilizzata. Con questo modello vengono superati entrambi i limiti dei due precedenti, perché non ho più i problemi di concorrenza del <em>molti-a-uno</em> né limiti nella creazione di thread utente come nell' <em>uno-a-uno</em>. Col <em>molti-a-molti</em> posso infatti creare quanti thread voglio, che potranno comunque essere eseguiti in parallelo.
</li></ul><div  style='text-align: center;'><img src='../uploads/Uni/molti-a-molti.jpg' alt='' title='' /></div>
<div class='vspace'></div><div class='indent'>Una variante comune è quella del <em>modello a due livelli</em>, che mappa molti thread di livello utente verso un numero più piccolo o equivalente di kernel thread, ma permette anche di associarne alcuni in modalità <em>uno-a-uno</em>. 
</div><div  style='text-align: center;'><img src='../uploads/Uni/due-livelli.jpg' alt='' title='' /></div>
<p class='vspace'>Va da sé che questi modelli si applicano su sistemi multithread. In un sistema operativo con supporto per soli processi pesanti, occorre simularli a livello utente all'interno di un processo utilizzando una libreria di livello utente.
</p>
<div class='vspace'></div><h2>Cooperazione tra thread</h2>
<p>La cooperazione tra più thread può essere rappresentata secondo tre modelli di comportamento:
</p>
<div class='vspace'></div><ul><li><em>thread simmetrici</em>, in cui tutti i thread sono equipotenti, ovvero posso scegliere di attivarne uno qualunque per servire una richiesta esterna. Ad esempio, se in un server web mi arriva la richiesta di un client, utilizzerò uno dei thread di servizio disponibili per ascoltare la richiesta, caricare la pagina dal disco e reinviargliela.
<div class='vspace'></div></li><li><em>thread gerarchici</em>, con la divisione in due livelli tra coordinatori e lavoratori (worker thread). I primi coordinano i lavori (chi fa cosa, come e quando), ricevendo le richieste esterne e decidendo eventualmente a quale thread lavoratore indirizzarle; i secondi eseguono. Notare come questo modella permetta di avere il coordinatore praticamente sempre reperibile, dal momento che evade rapidamente le sue occupazioni. A livello implementativo è conveniente mappare il thread coordinatore nel kernel, e i worker nel livello utente.
<div class='vspace'></div></li><li><em>thread in pipeline</em>, dove ogni thread svolge una porzione del lavoro complessivo, essendo specializzato in un preciso sottoinsieme delle funzioni dell'elaborazione complessiva. Avviene dunque una suddivisione del lavoro, come in una catena di montaggio. Ottengo così una distribuzione dei lavori ed un throughput elevato, dal momento che ogni thread torna in attesa di soddisfare nuove richieste dopo il tempo minimale che impiega per svolgere la sua piccola sequenza di operazioni (il concetto è fare poche operazioni, ma spesso).
</li></ul><div class='vspace'></div><h2>Gestione dei thread</h2>
<p>Vedremo ora le varie funzioni messe a disposizione per la gestione dei thread.
</p>
<div class='vspace'></div><h3>Creazione</h3>
<p>La sintassi della chiamata di sistema per creare un nuovo thread è uguale a quella dei processi, ovvero <em>fork()</em>. La semantica cambia invece sensibilmente. Il problema è il seguente: se il thread di un programma chiama una <code class='escaped'>fork()</code>, verrà creato un nuovo processo con la copia di tutti i thread, o un processo pesante composto da quell'unico thread che aveva lanciato la fork? Dipende dal sistema operativo. Ad esempio nei sistemi Unix viene data la possibilità di scegliere tra le due alternative fornendo due funzioni <code class='escaped'>fork()</code> distinte: quella che duplica tutti i thread e quella che duplica solo il thread che effettua la chiamata di sistema.
</p>
<div class='vspace'></div><h3>Esecuzione</h3>
<p>La funzione di esecuzione <em>exec()</em> riveste il thread di un nuovo codice, rimpiazzando quello di partenza. In questo caso oltre la sintassi rimane invariata anche la semantica rispetto alla corrispondente chiamata di sistema per i processi.<br />A questo punto diventa più semplice decidere quale tipo di <code class='escaped'>fork()</code> andare ad eseguire:
</p><ul><li>se dovrò chiamare una <code class='escaped'>exec()</code> subito dopo la <code class='escaped'>fork()</code>, allora quest'ultima potrà essere benissimo quella che duplica il solo thread chiamante, dato che la prima operazione che eseguirà sarà cancellare sé stesso e caricare qualcos'altro
</li><li>se non viene chiamata alcuna <code class='escaped'>exec()</code> dopo la <code class='escaped'>fork()</code>, allora sarebbe più opportuno duplicare tutti i thread del processo padre.
</li></ul><p class='vspace'>Quindi, perché due thread appartenenti a uno stesso processo possano eseguire operazioni diverse, posso adottare due strategie: faccio delle <em>call()</em> a porzioni diverse del codice condiviso, oppure utilizzo le <em>exec()</em>.
</p>
<div class='vspace'></div><h3>Cancellazione</h3>
<p>Cancellare un thread significa terminarlo prima che abbia completato la sua esecuzione, ad esempio in un browser web quando clicco sul pulsante di interruzione del caricamento della pagina.<br />Il thread che sta per essere cancellato viene spesso chiamato <em>thread target</em>, e la sua cancellazione può avvenire in due modalità:
</p><ul><li><em>asincrona</em>, con terminazione immediata indipedentemente dall'operazione che sta svolgendo in quel momento;
</li><li><em>differita</em>, inserendo il thread in una specie di "lista nera" e verificando periodicamente se sono in punti del codice in cui è possibile terminarlo. Altrimenti attendo semplicemente che il thread finisca la sua computazione, ottenendo di fatto una terminazione ordinaria.
</li></ul><div class='vspace'></div><h3>Sincronizzazione e comunicazione</h3>
<p>Se ho due processi che lavorano insieme ed ho un thread che vuole comunicare con l'altro processo, la comunicazione può avvenire con tutti i thread del processo destinatario, con un loro sottoinsieme o con uno specifico.
</p>
<div class='vspace'></div><h3>Processi leggeri</h3>
<p>Abbiamo visto come nel modello multithread molti-a-molti (così come in quello a due livelli, di cui è una variante) i thread a livello utente vengano mappati su un numero inferiore (o al più uguale) di kernel thread. Diventa dunque opportuna una coordinazione tra kernel e libreria dei thread, effettuando una loro schedulazione in modo da aggiustarne dinamicamente il numero nel kernel, migliorando così le prestazioni complessive del sistema.<br />Se il kernel supporta nativamente tale schedulazione non ci sono problemi, ma in caso contrario? Una soluzione potrebbe essere "mascherare" i thread da processi, così che il sistema operativo possa sfruttare gli algoritmi che già conosce e implementa per ottenere il multi-tasking. E' a questo scopo che in molti sistemi sono state introdotte delle strutture dati intermedie fra i thread a livello utente e quelli a livello kernel, detti <em>processi leggeri</em> (<em>lightweight process, LWP</em>). Dei processi essi detengono tutte quelle caratteristiche che lo rendono autonomo e passibile di context-switching, così da potervi applicare la schedulazione; non ha però un proprio spazio di indirizzamento, condividendo di fatto gran parte della memoria con gli altri thread (livello utente). Sull'altro livello, l'LWP appare alla libreria dei thread utente come una sorta di <em>processore virtuale</em> grazie al quale l'applicazione può schedulare l'esecuzione di un thread utente. Va infine ricordato che la mappatura "thread utente - processo leggero" segue il modello uno-a-uno.
</p>
<div class='vspace'></div><hr />
<p><a class='wikilink' href='SistemiOperativi.html'>Torna alla pagina di Sistemi Operativi</a>
</p>
</div>

  <div id='printfoot'>
    <div class='printview'>(Printable View of <span style='white-space:nowrap;'>http://www.swappa.it/wiki/Uni/SO-Thread)</span></div>
  </div>
</body>
</html>
